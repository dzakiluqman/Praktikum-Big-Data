{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2f37ad-0766-49dd-8e0a-bd5e0671346f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/10 21:48:02 WARN Utils: Your hostname, jaki-ThinkPad-T490 resolves to a loopback address: 127.0.1.1; using 192.168.0.115 instead (on interface wlp0s20f3)\n",
      "25/09/10 21:48:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/jaki/anaconda3/envs/jaki/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "25/09/10 21:48:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/10 21:48:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|       James|     Sales|  3000|\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|     Sales|  4100|\n",
      "|       Maria|   Finance|  3000|\n",
      "+------------+----------+------+\n",
      "\n",
      "root\n",
      " |-- EmployeeName: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+----------+----------------+\n",
      "|summary|EmployeeName|Department|          Salary|\n",
      "+-------+------------+----------+----------------+\n",
      "|  count|           4|         4|               4|\n",
      "|   mean|        null|      null|          3675.0|\n",
      "| stddev|        null|      null|805.708797684788|\n",
      "|    min|       James|   Finance|            3000|\n",
      "|    max|      Robert|     Sales|            4600|\n",
      "+-------+------------+----------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
    "\n",
    "data = [\n",
    "    ('James', 'Sales', 3000),\n",
    "    ('Michael', 'Sales', 4600),\n",
    "    ('Robert', 'Sales', 4100),\n",
    "    ('Maria', 'Finance', 3000)\n",
    "]\n",
    "columns = ['EmployeeName', 'Department', 'Salary']\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ffc106-8bba-4ea9-aa6b-ffb7272e9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|EmployeeName|Salary|\n",
      "+------------+------+\n",
      "|       James|  3000|\n",
      "|     Michael|  4600|\n",
      "|      Robert|  4100|\n",
      "|       Maria|  3000|\n",
      "+------------+------+\n",
      "\n",
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|     Sales|  4100|\n",
      "+------------+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|Department|AvgSalary|\n",
      "+----------+---------+\n",
      "|     Sales|   3900.0|\n",
      "|   Finance|   3000.0|\n",
      "+----------+---------+\n",
      "\n",
      "+----------+-----------+---------+\n",
      "|Department|TotalSalary|MaxSalary|\n",
      "+----------+-----------+---------+\n",
      "|     Sales|      11700|     4600|\n",
      "|   Finance|       3000|     3000|\n",
      "+----------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.select('EmployeeName', 'Salary').show()\n",
    "\n",
    "df.filter(df['Salary'] > 3000).show()\n",
    "\n",
    "df.groupBy('Department').agg(F.avg('Salary').alias('AvgSalary')).show()\n",
    "\n",
    "df.groupBy('Department').agg(\n",
    "    F.sum('Salary').alias('TotalSalary'),\n",
    "    F.max('Salary').alias('MaxSalary')\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9c382b-3c6e-48ea-b988-fbdd976fe4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+-----------+\n",
      "|EmployeeName|Department|Salary|SalaryBonus|\n",
      "+------------+----------+------+-----------+\n",
      "|       James|     Sales|  3000|      300.0|\n",
      "|     Michael|     Sales|  4600|      460.0|\n",
      "|      Robert|     Sales|  4100|      410.0|\n",
      "|       Maria|   Finance|  3000|      300.0|\n",
      "+------------+----------+------+-----------+\n",
      "\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "|       James|     Sales|  3000|      300.0|           3300.0|\n",
      "|     Michael|     Sales|  4600|      460.0|           5060.0|\n",
      "|      Robert|     Sales|  4100|      410.0|           4510.0|\n",
      "|       Maria|   Finance|  3000|      300.0|           3300.0|\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bonus = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n",
    "df_bonus.show()\n",
    "\n",
    "df_total = df_bonus.withColumn('TotalCompensation', df_bonus['Salary'] + df_bonus['SalaryBonus'])\n",
    "df_total.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef5cad3-3c6a-43a4-825d-5397b72442c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+----+\n",
      "|EmployeeName|Department|Salary|Rank|\n",
      "+------------+----------+------+----+\n",
      "|       James|     Sales|  3000|   1|\n",
      "|      Robert|     Sales|  4100|   2|\n",
      "|     Michael|     Sales|  4600|   3|\n",
      "|       Maria|   Finance|  3000|   1|\n",
      "+------------+----------+------+----+\n",
      "\n",
      "+------------+----------+------+------------+\n",
      "|EmployeeName|Department|Salary|RunningTotal|\n",
      "+------------+----------+------+------------+\n",
      "|       James|     Sales|  3000|        3000|\n",
      "|      Robert|     Sales|  4100|        7100|\n",
      "|     Michael|     Sales|  4600|       11700|\n",
      "|       Maria|   Finance|  3000|        3000|\n",
      "+------------+----------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "windowSpec = Window.partitionBy('Department').orderBy('Salary')\n",
    "\n",
    "df.withColumn('Rank', F.rank().over(windowSpec)).show()\n",
    "\n",
    "df.withColumn('RunningTotal', F.sum('Salary').over(windowSpec.rowsBetween(Window.unboundedPreceding, Window.currentRow))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e0ab5e-853d-48ee-a308-22888a6c5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaki/anaconda3/envs/jaki/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.13)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ruchi798/data-science-job-salaries?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7.37k/7.37k [00:00<00:00, 3.26MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting model files...\n",
      "Dataset downloaded to: /home/jaki/.cache/kagglehub/datasets/ruchi798/data-science-job-salaries/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Contoh data:\n",
      "+---+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|_c0|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|  0|     2020|              MI|             FT|      Data Scientist| 70000|            EUR|        79833|                DE|           0|              DE|           L|\n",
      "|  1|     2020|              SE|             FT|Machine Learning ...|260000|            USD|       260000|                JP|           0|              JP|           S|\n",
      "|  2|     2020|              SE|             FT|   Big Data Engineer| 85000|            GBP|       109024|                GB|          50|              GB|           M|\n",
      "|  3|     2020|              MI|             FT|Product Data Analyst| 20000|            USD|        20000|                HN|           0|              HN|           S|\n",
      "|  4|     2020|              SE|             FT|Machine Learning ...|150000|            USD|       150000|                US|          50|              US|           L|\n",
      "+---+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "🧾 Struktur data:\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n",
      "💡 Rata-rata gaji berdasarkan pengalaman:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/10 21:55:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      " Schema: _c0, work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jaki/.cache/kagglehub/datasets/ruchi798/data-science-job-salaries/versions/1/ds_salaries.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|experience_level|        avg_salary|\n",
      "+----------------+------------------+\n",
      "|              EX|199392.03846153847|\n",
      "|              MI| 87996.05633802817|\n",
      "|              EN|61643.318181818184|\n",
      "|              SE|138617.29285714286|\n",
      "+----------------+------------------+\n",
      "\n",
      "💡 10 Pekerjaan dengan gaji tertinggi:\n",
      "+--------------------+----------+\n",
      "|           job_title|max_salary|\n",
      "+--------------------+----------+\n",
      "|Principal Data En...|    600000|\n",
      "|Financial Data An...|    450000|\n",
      "|  Research Scientist|    450000|\n",
      "|Applied Machine L...|    423000|\n",
      "|Principal Data Sc...|    416000|\n",
      "|      Data Scientist|    412000|\n",
      "| Data Analytics Lead|    405000|\n",
      "|Applied Data Scie...|    380000|\n",
      "|Director of Data ...|    325000|\n",
      "|       Data Engineer|    324000|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "💡 Total gaji per lokasi perusahaan:\n",
      "+----------------+------------+\n",
      "|company_location|total_salary|\n",
      "+----------------+------------+\n",
      "|              DZ|      100000|\n",
      "|              UA|       13400|\n",
      "|              RO|       60000|\n",
      "|              NL|      219783|\n",
      "|              PL|      264330|\n",
      "|              MX|       96370|\n",
      "|              EE|       32974|\n",
      "|              CN|      143331|\n",
      "|              AT|      291683|\n",
      "|              IQ|      100000|\n",
      "|              RU|      315000|\n",
      "|              HR|       45618|\n",
      "|              CZ|      101874|\n",
      "|              PT|      191175|\n",
      "|              CL|       40038|\n",
      "|              PK|       40000|\n",
      "|              AU|      324128|\n",
      "|              CA|     2994712|\n",
      "|              GB|     3834403|\n",
      "|              MT|       28369|\n",
      "+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "💡 Daftar pekerjaan dengan gaji > $200.000:\n",
      "+--------------------+------------------+-------------+\n",
      "|           job_title|employee_residence|salary_in_usd|\n",
      "+--------------------+------------------+-------------+\n",
      "|Machine Learning ...|                JP|       260000|\n",
      "|Director of Data ...|                US|       325000|\n",
      "|  Research Scientist|                US|       450000|\n",
      "|Machine Learning ...|                US|       250000|\n",
      "|      Data Scientist|                US|       412000|\n",
      "|        Head of Data|                US|       235000|\n",
      "|         ML Engineer|                US|       270000|\n",
      "|  Lead Data Engineer|                US|       276000|\n",
      "|Financial Data An...|                US|       450000|\n",
      "|Machine Learning ...|                US|       225000|\n",
      "|Principal Data Sc...|                US|       220000|\n",
      "|Data Science Manager|                US|       240000|\n",
      "|Applied Machine L...|                US|       423000|\n",
      "|        Head of Data|                RU|       230000|\n",
      "|Director of Data ...|                US|       250000|\n",
      "|Principal Data Sc...|                US|       235000|\n",
      "|Machine Learning ...|                US|       225000|\n",
      "|Principal Data Sc...|                US|       416000|\n",
      "|         ML Engineer|                US|       256000|\n",
      "|Principal Data En...|                US|       600000|\n",
      "+--------------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, max, sum\n",
    "\n",
    "# Download dataset dari Kaggle\n",
    "path = kagglehub.dataset_download(\"ruchi798/data-science-job-salaries\")\n",
    "print(\"Dataset downloaded to:\", path)\n",
    "\n",
    "# Inisialisasi SparkSession\n",
    "spark = SparkSession.builder.appName(\"Tugas5_DS_Salaries\").getOrCreate()\n",
    "\n",
    "# Load file CSV\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(f\"{path}/ds_salaries.csv\")\n",
    "\n",
    "# Tampilkan beberapa baris awal\n",
    "print(\"📊 Contoh data:\")\n",
    "df.show(5)\n",
    "\n",
    "# Tampilkan skema kolom\n",
    "print(\"🧾 Struktur data:\")\n",
    "df.printSchema()\n",
    "\n",
    "# 💡 Insight 1: Rata-rata gaji per experience level\n",
    "print(\"💡 Rata-rata gaji berdasarkan pengalaman:\")\n",
    "df.groupBy(\"experience_level\").agg(avg(\"salary_in_usd\").alias(\"avg_salary\")).show()\n",
    "\n",
    "# 💡 Insight 2: 10 Pekerjaan dengan gaji tertinggi\n",
    "print(\"💡 10 Pekerjaan dengan gaji tertinggi:\")\n",
    "df.groupBy(\"job_title\").agg(max(\"salary_in_usd\").alias(\"max_salary\")) \\\n",
    "  .orderBy(\"max_salary\", ascending=False).show(10)\n",
    "\n",
    "# 💡 Insight 3: Total salary berdasarkan lokasi perusahaan\n",
    "print(\"💡 Total gaji per lokasi perusahaan:\")\n",
    "df.groupBy(\"company_location\").agg(sum(\"salary_in_usd\").alias(\"total_salary\")).show()\n",
    "\n",
    "# 💡 Insight 4: Data gaji lebih dari $200k\n",
    "print(\"💡 Daftar pekerjaan dengan gaji > $200.000:\")\n",
    "df.filter(df[\"salary_in_usd\"] > 200000).select(\"job_title\", \"employee_residence\", \"salary_in_usd\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31062111-4001-4e83-b54b-881ed4f22d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ca915-eec6-4f85-8751-e391503be685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980f80a-77c7-4e11-9898-d245d76e9fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3689338-cda3-4814-bd14-4e8843d7e6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6295a8-f217-447c-9395-6743b3f5a8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
